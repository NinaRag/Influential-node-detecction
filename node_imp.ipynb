{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/NinaRag/Influential-node-detection/blob/main/node_imp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FsDRfqHTE28H"
      },
      "source": [
        "# Node Importance in a Citation network"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FbkGlSXs_VSx",
        "outputId": "7bb6c25c-765a-48bb-d118-a16cf0b158fc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rxcIsJgnmvGD"
      },
      "outputs": [],
      "source": [
        "#Directed graph definition using networkx library\n",
        "import networkx as nx\n",
        "G = nx.DiGraph()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "IPMb2_Ai-2OG",
        "outputId": "7a6b5fff-3c27-4d58-b806-034e55ada0a5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "''"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BxtzkILjOv57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 561
        },
        "outputId": "2d1923ff-7e28-4259-f73a-18f92b29f741"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/scipy/sparse/linalg/eigen/arpack/arpack.py:1269: RuntimeWarning: k >= N - 1 for N * N square matrix. Attempting to use scipy.linalg.eig instead.\n",
            "  RuntimeWarning)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-185-94a550628535>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m       \u001b[0meigenvector_centrality\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meigenvector_centrality_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1e-03\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m       \u001b[0mv2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigenvector_centrality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m       \u001b[0mk2\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meigenvector_centrality\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/networkx/algorithms/centrality/eigenvector.py\u001b[0m in \u001b[0;36meigenvector_centrality_numpy\u001b[0;34m(G, weight, max_iter, tol)\u001b[0m\n\u001b[1;32m    224\u001b[0m     \u001b[0mM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_scipy_sparse_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnodelist\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mG\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m     eigenvalue, eigenvector = sp.sparse.linalg.eigs(\n\u001b[0;32m--> 226\u001b[0;31m         \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwhich\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"LR\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtol\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    227\u001b[0m     )\n\u001b[1;32m    228\u001b[0m     \u001b[0mlargest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meigenvector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreal\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/scipy/sparse/linalg/eigen/arpack/arpack.py\u001b[0m in \u001b[0;36meigs\u001b[0;34m(A, k, M, sigma, which, v0, ncv, maxiter, tol, return_eigenvectors, Minv, OPinv, OPpart)\u001b[0m\n\u001b[1;32m   1270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0missparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mA\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1272\u001b[0;31m             raise TypeError(\"Cannot use scipy.linalg.eig for sparse A with \"\n\u001b[0m\u001b[1;32m   1273\u001b[0m                             \u001b[0;34m\"k >= N - 1. Use scipy.linalg.eig(A.toarray()) or\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m                             \" reduce k.\")\n",
            "\u001b[0;31mTypeError\u001b[0m: Cannot use scipy.linalg.eig for sparse A with k >= N - 1. Use scipy.linalg.eig(A.toarray()) or reduce k."
          ]
        }
      ],
      "source": [
        "# CHANGE 2721 TO ANOTHER COMMUNITY NUMBER 145.\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import csv\n",
        "import os\n",
        "import pandas as pd\n",
        "from pandas import *\n",
        "from numpy import asarray\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "# define data\n",
        "scaler = MinMaxScaler()\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/Datamining/community/'\n",
        "for i in [1483]:\n",
        "  filename = folder_path + \"nodes\"+str(i)+\".csv\"\n",
        "  if os.path.isfile(filename):\n",
        "    fold = '/content/drive/MyDrive/Datamining/norm/'\n",
        "    with open(fold +'norm_score'+str(i)+'.csv', 'w', ) as myfile:\n",
        "      wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "      wr.writerow([\"node\", \"dc\", \"pr\", \"eigenscore\"])\n",
        "      points1 =[]\n",
        "      points2 =[]\n",
        "      \n",
        "      with open(filename, \"r\", ) as myfile:\n",
        "      \n",
        "        data = pd.read_csv(filename, index_col=False) \n",
        "        points1 = list(data['edge1'])\n",
        "        points2 = list(data['edge2'])\n",
        "\n",
        "      \n",
        "      G = nx.DiGraph()\n",
        "        \n",
        "\n",
        "      for f, b in zip(points1,points2):\n",
        "        G.add_edge(f, b)\n",
        "\n",
        "      G.remove_edges_from(nx.selfloop_edges(G))\n",
        "      \n",
        "      \n",
        "      degree_centrality = nx.degree_centrality(G)\n",
        "      v1 = list(degree_centrality.values())\n",
        "\n",
        "      k1 = list(degree_centrality.keys())\n",
        "\n",
        "      page_rank = nx.pagerank(G)\n",
        "      v = list(page_rank.values())\n",
        "\n",
        "      k = list(page_rank.keys())\n",
        "\n",
        "      \n",
        "      eigenvector_centrality = nx.eigenvector_centrality_numpy(G, tol=1e-03)\n",
        "      v2 = list(eigenvector_centrality.values())\n",
        "      k2= list(eigenvector_centrality.keys())\n",
        "\n",
        "      for i in range(0,len(k)):\n",
        "        b1 = (v1[i]-min(v1))/(max(v1)-min(v1))\n",
        "        b = (v[i]-min(v))/(max(v)-min(v))\n",
        "        b2 = (v2[i]-min(v2))/(max(v2)-min(v2))\n",
        "        wr.writerow([k[i],b1,b,b2])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DAE-DnhajWi3"
      },
      "outputs": [],
      "source": [
        "# Read the norm score csv\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pandas import *\n",
        "from csv import reader\n",
        "\n",
        "folder_path = '/content/drive/MyDrive/Datamining/norm/'\n",
        "for sn in [1508]:\n",
        "  filename = folder_path + \"norm_score\"+str(sn)+\".csv\"\n",
        "  if os.path.isfile(filename):\n",
        "    \n",
        "    df = read_csv(filename)\n",
        "    \n",
        "    l=[]\n",
        "\n",
        "    for i in range(0, len(df)):\n",
        "      l.append([df[\"node\"][i],df[\"dc\"][i],df[\"pr\"][i],df[\"eigenscore\"][i]])\n",
        "\n",
        "    ldict = {li[0]: li[1:] for li in l}\n",
        "    \n",
        "    nodes_g = list(df[\"node\"])\n",
        "\n",
        "    dc_diff = []\n",
        "    dcdiff = {}\n",
        "    pr_diff = []\n",
        "    ev_diff = []\n",
        "    \n",
        "    for i in range(0,len(nodes_g)):\n",
        "      for j in range(i, len(nodes_g)):\n",
        "        \n",
        "        dc_diff.append([nodes_g[i], nodes_g[j], ldict[nodes_g[i]][0]-ldict[nodes_g[j]][0]])\n",
        "        pr_diff.append([nodes_g[i], nodes_g[j], ldict[nodes_g[i]][1]-ldict[nodes_g[j]][1]])\n",
        "        ev_diff.append([nodes_g[i], nodes_g[j], ldict[nodes_g[i]][2]-ldict[nodes_g[j]][2]])\n",
        "\n",
        "    for i in range(len(dc_diff)):\n",
        "      if(dc_diff[i] !=None):\n",
        "        if(dc_diff[i][2]<0):\n",
        "          temp = dc_diff[i][0]\n",
        "          dc_diff[i][0] = dc_diff[i][1]\n",
        "          dc_diff[i][1] = temp\n",
        "        \n",
        "        dc_diff[i][2] = abs(dc_diff[i][2])\n",
        "\n",
        "    for i in range(len(pr_diff)):\n",
        "      if(pr_diff[i] !=None):\n",
        "        if(pr_diff[i][2]<0):\n",
        "          temp = pr_diff[i][0]\n",
        "          pr_diff[i][0] = pr_diff[i][1]\n",
        "          pr_diff[i][1] = temp\n",
        "        \n",
        "        pr_diff[i][2] = abs(pr_diff[i][2])\n",
        "\n",
        "    for i in range(len(ev_diff)):\n",
        "      if(ev_diff[i] !=None):\n",
        "        if(ev_diff[i][2]<0):\n",
        "          temp = ev_diff[i][0]\n",
        "          ev_diff[i][0] = ev_diff[i][1]\n",
        "          ev_diff[i][1] = temp\n",
        "        \n",
        "        ev_diff[i][2] = abs(ev_diff[i][2])\n",
        "\n",
        "    dc_diff_trun = [i for i in dc_diff if i[2] != 0]\n",
        "    pr_diff_trun = [i for i in pr_diff if i[2] != 0]\n",
        "    ev_diff_trun = [i for i in ev_diff if i[2] != 0]\n",
        "\n",
        "    dc_copy4 = dc_diff_trun\n",
        "    pr_copy4 = pr_diff_trun\n",
        "    ev_copy4 = ev_diff_trun\n",
        "\n",
        "\n",
        "    for i in range(len(dc_diff)):\n",
        "      if(dc_diff[i] !=None):\n",
        "        if(dc_diff[i][2]<0):\n",
        "          temp = dc_diff[i][0]\n",
        "          dc_diff[i][0] = dc_diff[i][1]\n",
        "          dc_diff[i][1] = temp\n",
        "        \n",
        "        dc_diff[i][2] = abs(dc_diff[i][2])\n",
        "\n",
        "    for i in range(len(pr_diff)):\n",
        "      if(pr_diff[i] !=None):\n",
        "        if(pr_diff[i][2]<0):\n",
        "          temp = pr_diff[i][0]\n",
        "          pr_diff[i][0] = pr_diff[i][1]\n",
        "          pr_diff[i][1] = temp\n",
        "        \n",
        "        pr_diff[i][2] = abs(pr_diff[i][2])\n",
        "\n",
        "    for i in range(len(ev_diff)):\n",
        "      if(ev_diff[i] !=None):\n",
        "        if(ev_diff[i][2]<0):\n",
        "          temp = ev_diff[i][0]\n",
        "          ev_diff[i][0] = ev_diff[i][1]\n",
        "          ev_diff[i][1] = temp\n",
        "        \n",
        "        ev_diff[i][2] = abs(ev_diff[i][2])\n",
        "    \n",
        "    folder_path1 = '/content/drive/MyDrive/Datamining/pref/'\n",
        "\n",
        "    with open(folder_path1+'prefscore_dc'+str(sn)+'.csv', 'w', ) as myfile:\n",
        "      wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "      wr.writerow([\"node1\", \"node2\",\"preference relation\"])\n",
        "      for i in range(0,len(dc_copy4)):\n",
        "        if(dc_copy4[i] ==None):\n",
        "          wr.writerow([None,None,None])\n",
        "        else:\n",
        "          wr.writerow([dc_copy4[i][0],dc_copy4[i][1],dc_copy4[i][2]])\n",
        "\n",
        "    with open(folder_path1+'prefscore_pr'+str(sn)+'.csv', 'w',  ) as myfile:\n",
        "      wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "      wr.writerow([\"node1\", \"node2\",\"preference relation (pr)\"])\n",
        "      for i in range(0,len(pr_copy4)):\n",
        "        if(pr_copy4[i] ==None):\n",
        "          wr.writerow([None,None,None])\n",
        "        else:\n",
        "          wr.writerow([pr_copy4[i][0],pr_copy4[i][1],pr_copy4[i][2]])\n",
        "\n",
        "    with open(folder_path1+'prefscore_ev'+str(sn)+'.csv', 'w', ) as myfile:\n",
        "      wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "      wr.writerow([\"node1\", \"node2\",\"preference relation (ev)\"])\n",
        "      for i in range(0,len(ev_copy4)):\n",
        "        if(ev_copy4[i] ==None):\n",
        "          wr.writerow([None,None,None])\n",
        "        else:\n",
        "          wr.writerow([ev_copy4[i][0],ev_copy4[i][1],ev_copy4[i][2]])\n",
        "\n",
        "\n",
        "    x = [dc_copy4[i][0] for i in range(len(dc_copy4))]\n",
        "    y = [dc_copy4[i][1] for i in range(len(dc_copy4))]\n",
        "    z = [dc_copy4[i][2] for i in range(len(dc_copy4))]\n",
        "\n",
        "    x1 = [pr_copy4[i][0] for i in range(len(pr_copy4))]\n",
        "    y1 = [pr_copy4[i][1] for i in range(len(pr_copy4))]\n",
        "    z1 = [pr_copy4[i][2] for i in range(len(pr_copy4))]\n",
        "\n",
        "    x2 = [ev_copy4[i][0] for i in range(len(ev_copy4))]\n",
        "    y2 = [ev_copy4[i][1] for i in range(len(ev_copy4))]\n",
        "    z2 = [ev_copy4[i][2] for i in range(len(ev_copy4))]\n",
        "\n",
        "    n=nodes_g\n",
        "    \n",
        "    x_ = [row[0] for row in dc_diff]\n",
        "    y_ = [row[1] for row in dc_diff]\n",
        "    z_ = [row[2] for row in dc_diff]\n",
        "    xy = list(zip(x_,y_))\n",
        "\n",
        "    x1_ = [row[0] for row in pr_diff]\n",
        "    y1_ = [row[1] for row in pr_diff]\n",
        "    z1_ = [row[2] for row in pr_diff]\n",
        "    x1y1 = list(zip(x1_,y1_))\n",
        "\n",
        "    x2_ = [row[0] for row in ev_diff]\n",
        "    y2_ = [row[1] for row in ev_diff]\n",
        "    z2_ = [row[2] for row in ev_diff]\n",
        "    x2y2 = list(zip(x2_,y2_))\n",
        "\n",
        "    dict1={}\n",
        "    xn = list(set(n) - set(x_))\n",
        "    for i in x_:\n",
        "        dict1[i] = []\n",
        "\n",
        "\n",
        "    for (i,j) in zip(x_,y_):\n",
        "        dict1[i].append(j)\n",
        "\n",
        "    keys = sorted(dict1.keys())\n",
        "    size = len(n)\n",
        "\n",
        "    matrix = np.zeros([size,size])\n",
        "\n",
        "    for (a, b,c,d),c1 in zip([(keys.index(a), keys.index(b),a,b) for a, row in dict1.items() for b in row],z_):\n",
        "\n",
        "        \n",
        "        i1 = xy.index((c,d))\n",
        "        \n",
        "        matrix[a][b] = z_[i1]\n",
        "\n",
        "    matrix = np.asarray(matrix)\n",
        "    folder2 = '/content/drive/MyDrive/Datamining/matrix/'\n",
        "    folder3 = '/content/drive/MyDrive/Datamining/cpmat/'\n",
        "    np.savetxt(folder2+\"matrix_dc\"+str(sn)+\".csv\", matrix, delimiter=\",\", fmt='%1.5f')\n",
        "    \n",
        "\n",
        "    dict2={}\n",
        "    xn1 = list(set(n) - set(x1))\n",
        "\n",
        "    for i in x1_:\n",
        "        dict2[i] = []\n",
        "\n",
        "    for (i,j) in zip(x1_,y1_):\n",
        "        dict2[i].append(j)\n",
        "\n",
        "    keys = sorted(dict2.keys())\n",
        "    size = len(n)\n",
        "    matrix1 = np.zeros([size,size])\n",
        "    qq=list(dict2.items())\n",
        "    for (a, b,c,d),c1 in zip([(keys.index(a), keys.index(b),a,b) for a, row in dict2.items() for b in row],z1_):\n",
        "\n",
        "        \n",
        "        i1 = x1y1.index((c,d))\n",
        "        \n",
        "        matrix1[a][b] = z1_[i1]\n",
        "\n",
        "    matrix1 = np.asarray(matrix1)\n",
        "    np.savetxt(folder2+\"matrix_pr\"+str(sn)+\".csv\", matrix1, delimiter=\",\", fmt='%1.5f')\n",
        "    \n",
        "    dict3={}\n",
        "    xn2 = list(set(n) - set(x2))\n",
        "    for i in x2_:\n",
        "        dict3[i] = []\n",
        "\n",
        "    for (i,j) in zip(x2_,y2_):\n",
        "        dict3[i].append(j)\n",
        "\n",
        "    keys = sorted(dict3.keys())\n",
        "    size = len(n)\n",
        "\n",
        "    matrix2 = np.zeros([size,size])\n",
        "\n",
        "    for (a, b,c,d),c1 in zip([(keys.index(a), keys.index(b),a,b) for a, row in dict3.items() for b in row],z2_):\n",
        "\n",
        "        \n",
        "        i1 = x2y2.index((c,d))\n",
        "        \n",
        "        matrix2[a][b] = z2_[i1]\n",
        "\n",
        "    matrix2 = np.asarray(matrix2)\n",
        "    np.savetxt(folder2+\"matrix_ev\"+str(sn)+\".csv\", matrix2, delimiter=\",\", fmt='%1.5f')\n",
        "    cpmat = matrix+matrix1+matrix2\n",
        "    np.savetxt(folder3+\"cpmat\"+str(sn)+\".csv\", cpmat, delimiter=\",\", fmt='%1.5f')\n",
        "        \n",
        "    for i in range(len(cpmat)):\n",
        "      sum = cpmat.sum(axis=1)[i]\n",
        "      for j in range(len(cpmat)):\n",
        "        if (sum) == 0:\n",
        "          cpmat[i][j] == 0\n",
        "        else:\n",
        "          cpmat[i][j] = cpmat[i][j]/sum\n",
        "\n",
        "    cpmat.round(decimals=3)\n",
        "    num=len(nodes_g)\n",
        "\n",
        "    prob = [1/num]*num\n",
        "    prob =np.array(prob)\n",
        "    \n",
        "    \n",
        "    for t in range(0,10):\n",
        "      \n",
        "      prob = prob.dot(cpmat)\n",
        "      \n",
        "    final = {keys[i]: prob[i] for i in range(len(keys))}\n",
        "    \n",
        "    folder4 = '/content/drive/MyDrive/Datamining/ranking/'\n",
        "    with open(folder4+'ranking'+str(sn)+'.csv', 'w', ) as myfile:\n",
        "      wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
        "      \n",
        "      wr.writerows(sorted(final.items(), key =\n",
        "                lambda f:(f[1], f[0]))) "
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "node_imp",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}